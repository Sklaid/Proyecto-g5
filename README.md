# Plataforma de Observabilidad AIOps & SRE

[![Pipeline CI/CD](https://github.com/Sklaid/aiops-platform/workflows/CI/badge.svg)](https://github.com/Sklaid/aiops-platform/actions)
[![Licencia](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

Una plataforma de observabilidad y AIOps lista para producciÃ³n que combina instrumentaciÃ³n moderna con OpenTelemetry, monitoreo basado en SLI/SLO y detecciÃ³n inteligente de anomalÃ­as para reducir el Tiempo Medio de RecuperaciÃ³n (MTTR) hasta en un 70%.

**ğŸ“š [Ver Ãndice Completo de DocumentaciÃ³n](DOCUMENTATION_INDEX.md)** | **âœ… [Estado de ValidaciÃ³n](docs/validation-reports/VALIDATION_INDEX.md)** | **ğŸš€ [GuÃ­a de Inicio RÃ¡pido](docs/guides/QUICK_START.md)**

## ğŸ¯ DescripciÃ³n General

Esta plataforma proporciona **observabilidad completa de extremo a extremo** para aplicaciones distribuidas implementando los tres pilares de la observabilidad (MÃ©tricas, Trazas, Logs) y agregando detecciÃ³n inteligente de anomalÃ­as.

### Capacidades Clave

- **ğŸ“Š InstrumentaciÃ³n OpenTelemetry**: RecopilaciÃ³n estandarizada y neutral de mÃ©tricas y trazas distribuidas
- **ğŸ’¾ Almacenamiento de MÃ©tricas**: Prometheus para mÃ©tricas de series temporales con retenciÃ³n configurable (predeterminado: 15 dÃ­as)
- **ğŸ” Almacenamiento de Trazas**: Grafana Tempo para almacenamiento eficiente de trazas distribuidas
- **ğŸ“ˆ VisualizaciÃ³n**: Dashboards preconfigurados de Grafana para SLIs, SLOs, presupuestos de error y rendimiento de aplicaciones
- **ğŸš¨ Alertas Inteligentes**: Alertas multi-ventana basadas en SLO y detecciÃ³n de anomalÃ­as basada en ML
- **ğŸ¤– AIOps**: DetecciÃ³n automÃ¡tica de anomalÃ­as usando algoritmo Isolation Forest
- **ğŸ”„ IntegraciÃ³n CI/CD**: Pipeline completo de GitHub Actions con pruebas y despliegue automatizados
- **â˜¸ï¸ Cloud Native**: Listo para despliegue en Kubernetes con Helm charts y overlays de Kustomize

### Â¿Por QuÃ© Esta Plataforma?

**Problema:** El monitoreo tradicional te dice *quÃ©* estÃ¡ roto, pero no *por quÃ©* o *cÃ³mo arreglarlo rÃ¡pidamente*.

**SoluciÃ³n:** Esta plataforma proporciona:
- **DetecciÃ³n mÃ¡s rÃ¡pida de incidentes** (< 5 minutos vs horas)
- **AnÃ¡lisis rÃ¡pido de causa raÃ­z** (< 15 minutos con trazas distribuidas)
- **Alertas proactivas** (detecta problemas antes de que los usuarios los noten)
- **MTTR reducido** (mejora del 70-80% documentada)

## Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Demo App      â”‚ â”€â”€â”
â”‚  (Node.js)      â”‚   â”‚ MÃ©tricas y Trazas
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                      â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ OTel Collector   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚         â”‚
        MÃ©tricas   â”‚         â”‚    Trazas
                   â–¼         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚Prometheusâ”‚  â”‚  Tempo   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚         â”‚
                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                        â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Grafana   â”‚ â—„â”€â”€ Dashboards y Alertas
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–²
                        â”‚ Alertas de AnomalÃ­as
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Detector   â”‚
                 â”‚  AnomalÃ­as  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Componentes

### AplicaciÃ³n Demo
- AplicaciÃ³n Node.js Express con instrumentaciÃ³n OpenTelemetry
- Exporta mÃ©tricas (CPU, memoria, conteo de solicitudes, duraciÃ³n)
- Genera trazas distribuidas con propagaciÃ³n de contexto
- Simula patrones de trÃ¡fico realistas y escenarios de error

### OpenTelemetry Collector
- Recibe telemetrÃ­a vÃ­a OTLP (gRPC y HTTP)
- Procesa datos con batching y limitaciÃ³n de memoria
- Exporta mÃ©tricas a Prometheus y trazas a Tempo

### Prometheus
- Almacena mÃ©tricas de series temporales con retenciÃ³n de 15 dÃ­as
- Proporciona interfaz de consulta PromQL
- Soporta reglas de grabaciÃ³n para cÃ¡lculos de SLI

### Tempo
- Almacena trazas distribuidas eficientemente
- Proporciona API de consulta de trazas
- Se integra con Grafana para visualizaciÃ³n

### Grafana
- Dashboards preconfigurados para:
  - Monitoreo SLI/SLO con presupuestos de error
  - MÃ©tricas de rendimiento de aplicaciones
  - VisualizaciÃ³n de trazas distribuidas
- Reglas de alerta para violaciones de SLO y anomalÃ­as
- Datasources para Prometheus y Tempo

### Detector de AnomalÃ­as
- Servicio Python usando algoritmo Holt-Winters
- Detecta anomalÃ­as en mÃ©tricas automÃ¡ticamente
- Genera alertas con niveles de confianza
- Reduce MTTR a travÃ©s de insights predictivos

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

Antes de comenzar, asegÃºrate de tener:

- **Docker** (versiÃ³n 20.10+) y **Docker Compose** (versiÃ³n 2.0+) instalados
- Al menos **4GB de RAM disponible** (8GB recomendado para pruebas similares a producciÃ³n)
- Los siguientes **puertos disponibles**:
  - `3000` - AplicaciÃ³n Demo
  - `3001` - Grafana
  - `4317` - OTel Collector (gRPC)
  - `4318` - OTel Collector (HTTP)
  - `8889` - OTel Collector (exportador Prometheus)
  - `9090` - Prometheus
  - `3200` - Tempo
- **Git** para clonar el repositorio

### ğŸ³ Despliegue Local con Docker Compose

#### Paso 1: Clonar y Navegar

```bash
git clone https://github.com/Sklaid/aiops-sre-observability.git
cd aiops-sre-observability
```

#### Paso 2: Iniciar Todos los Servicios

```bash
# Iniciar todos los servicios en modo desacoplado
docker-compose up -d

# Ver los logs (opcional)
docker-compose logs -f
```

**Salida esperada:**
```
âœ” Container demo-app           Started
âœ” Container otel-collector     Started
âœ” Container prometheus         Started
âœ” Container tempo              Started
âœ” Container grafana            Started
âœ” Container anomaly-detector   Started
```

#### Paso 3: Verificar que los Servicios EstÃ¡n EjecutÃ¡ndose

```bash
# Verificar estado de servicios
docker-compose ps

# Todos los servicios deben mostrar estado "Up"
```

#### Paso 4: Generar TrÃ¡fico de Muestra

```powershell
# Windows PowerShell
.\scripts\traffic-generation\generate-continuous-traffic.ps1 -DurationSeconds 60 -RequestsPerSecond 5

# O usar el archivo batch
.\scripts\traffic-generation\generate-traffic.bat
```

```bash
# Linux/Mac
curl http://localhost:3000/api/users
curl http://localhost:3000/api/products
```

#### Paso 5: Acceder a los Servicios

| Servicio | URL | Credenciales | PropÃ³sito |
|---------|-----|-------------|---------|
| **Grafana** | http://localhost:3001 | `admin` / `grupo5_devops` | Dashboards y VisualizaciÃ³n |
| **Prometheus** | http://localhost:9090 | Ninguna | Interfaz de Consulta de MÃ©tricas |
| **Tempo** | http://localhost:3200 | Ninguna | API de Consulta de Trazas |
| **Demo App** | http://localhost:3000 | Ninguna | AplicaciÃ³n Instrumentada |

### ğŸ“Š Accediendo a los Dashboards de Grafana

1. **Abrir Grafana**: Navegar a http://localhost:3001
2. **Iniciar SesiÃ³n**: Usar credenciales `admin` / `grupo5_devops`
3. **Ver Dashboards**: Hacer clic en el menÃº (â˜°) â†’ Dashboards

**Dashboards Disponibles:**

| Dashboard | URL | DescripciÃ³n |
|-----------|-----|-------------|
| **Dashboard SLI/SLO** | http://localhost:3001/d/slo-dashboard | Monitorear SLIs, SLOs, presupuestos de error y tasas de consumo |
| **Rendimiento de AplicaciÃ³n** | http://localhost:3001/d/app-performance-dashboard | Latencia de solicitudes, throughput, errores y utilizaciÃ³n de recursos |
| **Trazas Distribuidas** | http://localhost:3001/d/distributed-tracing | AnÃ¡lisis de trazas y dependencias de servicios |

4. **Explorar Trazas**: Navegar a Explore (Ã­cono de brÃºjula) â†’ Seleccionar datasource Tempo â†’ Query: `{status=error}`

### ğŸ¬ Script de Demo RÃ¡pido

Â¿Quieres ver la plataforma en acciÃ³n? Ejecuta esta demo:

```powershell
# 1. Generar trÃ¡fico normal por 30 segundos
.\scripts\traffic-generation\generate-continuous-traffic.ps1 -DurationSeconds 30 -RequestsPerSecond 5

# 2. Generar algunos errores
.\scripts\traffic-generation\generate-test-errors.ps1 -ErrorCount 10 -DelaySeconds 1

# 3. Generar trÃ¡fico mixto (normal + errores)
.\scripts\traffic-generation\generate-mixed-traffic.ps1 -DurationSeconds 60 -ErrorRatePercent 15

# 4. Abrir todos los dashboards
.\scripts\utilities\open-all-dashboards.bat
```

Â¡Ahora observa cÃ³mo los dashboards se actualizan en tiempo real!

## ğŸ“ Estructura del Proyecto

```
aiops-sre-observability/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/              # Pipelines CI/CD de GitHub Actions
â”‚       â””â”€â”€ main-pipeline.yml   # Workflow principal de CI/CD
â”œâ”€â”€ demo-app/                   # AplicaciÃ³n demo Node.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.js           # AplicaciÃ³n principal con instrumentaciÃ³n OTel
â”‚   â”‚   â”œâ”€â”€ tracing.js         # ConfiguraciÃ³n de tracing OpenTelemetry
â”‚   â”‚   â””â”€â”€ metrics.js         # Definiciones de mÃ©tricas personalizadas
â”‚   â”œâ”€â”€ Dockerfile             # Build Docker multi-etapa
â”‚   â”œâ”€â”€ package.json           # Dependencias Node.js
â”‚   â””â”€â”€ README.md              # DocumentaciÃ³n de la app demo
â”œâ”€â”€ otel-collector/            # OpenTelemetry Collector
â”‚   â””â”€â”€ otel-collector-config.yaml  # ConfiguraciÃ³n del Collector
â”œâ”€â”€ prometheus/                # Base de datos de series temporales Prometheus
â”‚   â”œâ”€â”€ prometheus.yml         # ConfiguraciÃ³n de Prometheus
â”‚   â””â”€â”€ rules/                 # Reglas de grabaciÃ³n y alertas
â”‚       â”œâ”€â”€ recording-rules.yml
â”‚       â””â”€â”€ slo-alerts.yml
â”œâ”€â”€ tempo/                     # Trazas distribuidas Grafana Tempo
â”‚   â””â”€â”€ tempo.yaml            # ConfiguraciÃ³n de Tempo
â”œâ”€â”€ grafana/                   # VisualizaciÃ³n Grafana
â”‚   â””â”€â”€ provisioning/
â”‚       â”œâ”€â”€ datasources/       # Datasources autoconfigurados
â”‚       â”‚   â”œâ”€â”€ prometheus.yml
â”‚       â”‚   â””â”€â”€ tempo.yml
â”‚       â”œâ”€â”€ dashboards/        # ConfiguraciÃ³n de provisioning de dashboards
â”‚       â”‚   â””â”€â”€ json/          # Definiciones JSON de dashboards
â”‚       â”‚       â”œâ”€â”€ sli-slo-dashboard.json
â”‚       â”‚       â”œâ”€â”€ app-performance-dashboard.json
â”‚       â”‚       â””â”€â”€ distributed-tracing-dashboard.json
â”‚       â””â”€â”€ alerting/          # Reglas de alerta
â”‚           â””â”€â”€ rules.yml
â”œâ”€â”€ anomaly-detector/          # Servicio Python de detecciÃ³n de anomalÃ­as ML
â”‚   â”œâ”€â”€ anomaly_detector.py    # Algoritmo Isolation Forest
â”‚   â”œâ”€â”€ prometheus_client.py   # Cliente de consulta Prometheus
â”‚   â”œâ”€â”€ main.py               # Punto de entrada del servicio
â”‚   â”œâ”€â”€ requirements.txt      # Dependencias Python
â”‚   â”œâ”€â”€ Dockerfile            # Build Docker del servicio Python
â”‚   â””â”€â”€ test_anomaly_detector.py  # Pruebas unitarias
â”œâ”€â”€ k8s/                       # Manifiestos de despliegue Kubernetes
â”‚   â”œâ”€â”€ base/                  # Recursos base de Kubernetes
â”‚   â”‚   â”œâ”€â”€ demo-app-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ prometheus-statefulset.yaml
â”‚   â”‚   â”œâ”€â”€ tempo-statefulset.yaml
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ overlays/              # Overlays especÃ­ficos por entorno
â”‚       â”œâ”€â”€ dev/
â”‚       â””â”€â”€ prod/
â”œâ”€â”€ helm/                      # Charts Helm
â”‚   â””â”€â”€ aiops-platform/
â”‚       â”œâ”€â”€ Chart.yaml
â”‚       â”œâ”€â”€ values.yaml
â”‚       â”œâ”€â”€ values-dev.yaml
â”‚       â”œâ”€â”€ values-prod.yaml
â”‚       â””â”€â”€ templates/
â”œâ”€â”€ scripts/                   # Scripts de utilidad
â”‚   â”œâ”€â”€ validation/            # Scripts de validaciÃ³n
â”‚   â”œâ”€â”€ traffic-generation/    # Scripts de generaciÃ³n de trÃ¡fico
â”‚   â””â”€â”€ utilities/             # Scripts de utilidades
â”œâ”€â”€ docs/                      # DocumentaciÃ³n
â”‚   â”œâ”€â”€ validation-reports/    # Reportes de validaciÃ³n
â”‚   â”œâ”€â”€ guides/                # GuÃ­as de usuario
â”‚   â”œâ”€â”€ summaries/             # ResÃºmenes tÃ©cnicos
â”‚   â””â”€â”€ ci-cd/                 # DocumentaciÃ³n CI/CD
â”œâ”€â”€ docker-compose.yml         # OrquestaciÃ³n Docker Compose
â””â”€â”€ README.md                  # Este archivo
```

### Directorios Clave Explicados

| Directorio | PropÃ³sito | Archivos Clave |
|-----------|---------|-----------|
| `demo-app/` | AplicaciÃ³n Node.js instrumentada | `src/index.js`, `src/tracing.js` |
| `otel-collector/` | RecopilaciÃ³n y enrutamiento de telemetrÃ­a | `otel-collector-config.yaml` |
| `prometheus/` | Almacenamiento y consulta de mÃ©tricas | `prometheus.yml`, `rules/*.yml` |
| `tempo/` | Almacenamiento de trazas distribuidas | `tempo.yaml` |
| `grafana/` | VisualizaciÃ³n y dashboards | `provisioning/dashboards/json/*.json` |
| `anomaly-detector/` | DetecciÃ³n de anomalÃ­as basada en ML | `anomaly_detector.py` |
| `k8s/` | Despliegue Kubernetes | `base/*.yaml`, `overlays/*/` |
| `helm/` | Chart Helm para K8s | `aiops-platform/` |
| `.github/workflows/` | Pipelines CI/CD | `main-pipeline.yml` |
| `docs/` | DocumentaciÃ³n completa | `validation-reports/`, `guides/` |
| `scripts/` | Scripts de utilidad | `validation/`, `traffic-generation/`, `utilities/` |

## ğŸ¯ CaracterÃ­sticas Clave

### Monitoreo SLI/SLO
- **Seguimiento de percentiles de latencia** (P95, P99) con umbrales configurables
- **Monitoreo de tasas de error** y disponibilidad en tiempo real
- **CÃ¡lculo automÃ¡tico de presupuestos de error** basado en objetivos SLO
- **VisualizaciÃ³n de tasas de consumo** con anÃ¡lisis multi-ventana (1h, 6h, 24h)
- **ProyecciÃ³n de agotamiento de presupuesto** para tomar acciÃ³n proactiva

### Trazas Distribuidas
- **Trazado de solicitudes de extremo a extremo** a travÃ©s de todos los servicios
- **Mapeo de dependencias de servicios** para entender la arquitectura del sistema
- **AnÃ¡lisis de desglose de latencia** para identificar componentes lentos
- **Resaltado de trazas de error** para identificaciÃ³n rÃ¡pida de problemas
- **PropagaciÃ³n de contexto** a travÃ©s de lÃ­mites de servicios

### DetecciÃ³n Inteligente de AnomalÃ­as
- **Reconocimiento de patrones basado en ML** usando algoritmo Isolation Forest
- **Alertas automÃ¡ticas de anomalÃ­as** con puntuaciÃ³n de confianza
- **Aprendizaje de lÃ­nea base histÃ³rica** (7-30 dÃ­as de datos)
- **ReducciÃ³n de falsos positivos** a travÃ©s de anÃ¡lisis estadÃ­stico
- **Insights predictivos** para prevenir incidentes

### Alertas Basadas en SLO
- **Alertas multi-ventana multi-tasa-de-consumo** (mejor prÃ¡ctica de Google SRE)
- **Alertas de consumo de presupuesto de error** antes del agotamiento del presupuesto
- **Alertas de umbral de latencia** cuando P95 excede SLI
- **Alertas de detecciÃ³n de anomalÃ­as** para patrones inusuales
- **InformaciÃ³n contextual de alertas** para resoluciÃ³n mÃ¡s rÃ¡pida

## ğŸ“Š Entendiendo los Dashboards

### 1. Dashboard SLI/SLO

**PropÃ³sito:** Monitorear objetivos de nivel de servicio y consumo de presupuesto de error

**Paneles Clave:**

| Panel | QuÃ© Muestra | CÃ³mo Interpretar |
|-------|---------------|------------------|
| **Latencia de Solicitud (P95/P99)** | Latencia percentil 95 y 99 | Verde = Bueno (<200ms), Rojo = ViolaciÃ³n SLO |
| **Tasa de Ã‰xito** | % de solicitudes exitosas (no-5xx) | Objetivo: 99.9%, Amarillo <99.5%, Rojo <99% |
| **Presupuesto de Error Restante** | % de presupuesto de error restante para ventana de 30d | Verde >50%, Amarillo 20-50%, Rojo <20% |
| **Tasa de Error** | % de solicitudes fallidas (4xx, 5xx) | Objetivo: <1%, Alerta si >1% |
| **Tasa de Consumo (Multi-Ventana)** | Tasa de consumo de presupuesto de error | CrÃ­tico si >14.4x (presupuesto agotado en 2 dÃ­as) |
| **Tasa de Consumo Actual** | Tasa de consumo de 1 hora | Muestra tasa de consumo inmediata |
| **Presupuesto de Error (30d)** | Total, consumido y restante | Seguir presupuesto a lo largo del tiempo |
| **Cumplimiento SLO de Latencia** | % de solicitudes que cumplen SLO de latencia | Objetivo: 99.9% bajo 200ms |
| **Tasa de Solicitudes** | Throughput (solicitudes/segundo) | Monitorear patrones de trÃ¡fico |

**CÃ³mo Usar:**
1. **Verificar medidor de Tasa de Ã‰xito** - Â¿EstÃ¡ por encima del 99.9%?
2. **Monitorear Tasa de Consumo** - Â¿Se estÃ¡ acelerando?
3. **Revisar Presupuesto de Error** - Â¿CuÃ¡nto presupuesto queda?
4. **Investigar picos** - Hacer clic en anomalÃ­as para profundizar

**Umbrales de Alerta:**
- ğŸ”´ **CrÃ­tico**: Tasa de consumo >14.4x (presupuesto agotado en <2 dÃ­as)
- ğŸŸ¡ **Advertencia**: Tasa de consumo >6x (presupuesto agotado en <5 dÃ­as)
- ğŸŸ¢ **Normal**: Tasa de consumo <3x

### 2. Dashboard de Rendimiento de AplicaciÃ³n

**PropÃ³sito:** Monitorear salud de aplicaciÃ³n y utilizaciÃ³n de recursos

**Paneles Clave:**

| Panel | QuÃ© Muestra | CÃ³mo Interpretar |
|-------|---------------|------------------|
| **Histograma de DuraciÃ³n de Solicitud** | DistribuciÃ³n de latencias de solicitud | Buscar distribuciones bimodales o colas largas |
| **DuraciÃ³n de Solicitud por Endpoint** | Desglose de latencia por endpoint API | Identificar endpoints lentos |
| **Throughput por Endpoint** | Solicitudes/seg por endpoint | Entender patrones de trÃ¡fico |
| **Top 10 Endpoints** | Endpoints mÃ¡s frecuentemente llamados | Optimizar endpoints de alto trÃ¡fico |
| **Desglose de Tasa de Error** | Errores por cÃ³digo de estado (4xx, 5xx) | 4xx = errores de cliente, 5xx = errores de servidor |
| **DistribuciÃ³n de CÃ³digo de Estado** | GrÃ¡fico circular de cÃ³digos de respuesta | Saludable = mayormente 2xx |
| **UtilizaciÃ³n de CPU** | Uso de CPU a lo largo del tiempo | Alerta si >80% sostenido |
| **UtilizaciÃ³n de Memoria** | Uso de memoria a lo largo del tiempo | Alerta si >80% o creciendo |
| **Uso Actual de CPU/Heap** | Uso de recursos en tiempo real | Monitorear agotamiento de recursos |
| **Tasa Total de Solicitudes** | Throughput general | LÃ­nea base para planificaciÃ³n de capacidad |

**CÃ³mo Usar:**
1. **Verificar utilizaciÃ³n de recursos** - Â¿CPU/Memoria bajo 80%?
2. **Revisar desglose de errores** - Â¿EstÃ¡n aumentando los errores 5xx?
3. **Identificar endpoints lentos** - Â¿QuÃ© APIs necesitan optimizaciÃ³n?
4. **Monitorear throughput** - Â¿El trÃ¡fico estÃ¡ dentro del rango esperado?

### 3. Dashboard de Trazas Distribuidas

**PropÃ³sito:** Analizar flujos de solicitudes e identificar cuellos de botella

**Paneles Clave:**

| Panel | QuÃ© Muestra | CÃ³mo Interpretar |
|-------|---------------|------------------|
| **Tasa de Solicitud de Servicio** | Solicitudes/seg por servicio | Entender carga de servicio |
| **Desglose de Latencia** | P50, P95, P99 por servicio | Identificar servicios lentos |
| **Volumen de Trazas** | NÃºmero de trazas por estado | Monitorear recopilaciÃ³n de trazas |
| **Promedio de Spans por Traza** | Complejidad de solicitudes | MÃ¡s spans = mÃ¡s llamadas de servicio |

**CÃ³mo Usar BÃºsqueda de Trazas:**
1. Navegar a **Grafana Explore** (Ã­cono de brÃºjula)
2. Seleccionar datasource **Tempo**
3. Usar consultas:
   - `{status=error}` - Encontrar todas las trazas de error
   - `{service.name="demo-app"}` - Filtrar por servicio
   - `{http.status_code="500"}` - Encontrar errores especÃ­ficos
4. Hacer clic en una traza para ver lÃ­nea de tiempo detallada de spans
5. Analizar duraciÃ³n de span para encontrar cuellos de botella

**Consejos de AnÃ¡lisis de Trazas:**
- **Spans largos** = operaciones lentas (base de datos, API externa)
- **Muchos spans** = flujo de solicitud complejo
- **Spans de error** = excepciones o fallos
- **Atributos de span** = informaciÃ³n contextual (ID de usuario, endpoint, etc.)

### Mejores PrÃ¡cticas de Dashboards

1. **Comenzar con Dashboard SLI/SLO** - Â¿El servicio estÃ¡ saludable?
2. **Si hay violaciÃ³n de SLO, verificar Rendimiento de AplicaciÃ³n** - Â¿QuÃ© lo estÃ¡ causando?
3. **Usar Trazas Distribuidas para causa raÃ­z** - Â¿QuÃ© componente es lento?
4. **Monitorear tendencias a lo largo del tiempo** - Â¿Las cosas estÃ¡n mejorando o empeorando?
5. **Configurar alertas** - No depender de verificaciÃ³n manual

## Desarrollo

### Ejecutar Pruebas

#### Pruebas Unitarias
```bash
# Pruebas unitarias de la app demo
cd demo-app
npm test

# Pruebas del detector de anomalÃ­as
cd anomaly-detector
python -m pytest
```

#### Pruebas de IntegraciÃ³n
Las pruebas de integraciÃ³n verifican el pipeline completo de telemetrÃ­a desde la app demo a travÃ©s del collector hasta Prometheus y Tempo.

**Inicio RÃ¡pido (Windows):**
```cmd
cd demo-app
run-integration-tests.bat
```

**Inicio RÃ¡pido (Linux/Mac):**
```bash
cd demo-app
chmod +x run-integration-tests.sh
./run-integration-tests.sh
```

**EjecuciÃ³n Manual:**
```bash
# 1. Iniciar todos los servicios
docker-compose up -d

# 2. Esperar a que los servicios estÃ©n listos (30 segundos)

# 3. Ejecutar pruebas de integraciÃ³n
cd demo-app
npm run test:integration
```

**Lo que verifican las pruebas de integraciÃ³n:**
- âœ… El Collector recibe mÃ©tricas y trazas OTLP de la app demo
- âœ… Las mÃ©tricas se exportan en formato Prometheus
- âœ… Las mÃ©tricas de aplicaciÃ³n y personalizadas aparecen en Prometheus
- âœ… Las trazas se reenvÃ­an a Tempo con contexto preservado
- âœ… Las trazas de error se manejan correctamente
- âœ… Pipeline completo de telemetrÃ­a de extremo a extremo

Para informaciÃ³n detallada, ver [demo-app/INTEGRATION_TESTS.md](demo-app/INTEGRATION_TESTS.md)

### Construir ImÃ¡genes Docker
```bash
# Construir todas las imÃ¡genes
docker-compose build

# Construir servicio especÃ­fico
docker-compose build demo-app
```

### Ver Logs
```bash
# Todos los servicios
docker-compose logs -f

# Servicio especÃ­fico
docker-compose logs -f demo-app
```

## â˜¸ï¸ Despliegue en Kubernetes

Para despliegues de producciÃ³n en Kubernetes, proporcionamos dos opciones:

### OpciÃ³n 1: Helm Chart (Recomendado)

```bash
# Instalar con Helm
helm install aiops-platform ./helm/aiops-platform \
  --namespace observability \
  --create-namespace \
  --values helm/aiops-platform/values-prod.yaml

# Verificar despliegue
kubectl get pods -n observability

# Acceder a Grafana (despuÃ©s de que LoadBalancer obtenga IP externa)
kubectl get svc -n observability grafana
```

**CaracterÃ­sticas del Helm Chart:**
- Configuraciones parametrizadas para diferentes entornos
- Requests y lÃ­mites de recursos preconfigurados
- HorizontalPodAutoscaler para demo-app
- PersistentVolumeClaims para persistencia de datos
- ConfigMaps para todas las configuraciones de componentes

### OpciÃ³n 2: Kustomize

```bash
# Desplegar a desarrollo
kubectl apply -k k8s/overlays/dev

# Desplegar a producciÃ³n
kubectl apply -k k8s/overlays/prod

# Verificar despliegue
kubectl get all -n observability
```

**CaracterÃ­sticas de Kustomize:**
- Manifiestos base con overlays especÃ­ficos por entorno
- FÃ¡cil personalizaciÃ³n por entorno
- Estructura amigable con GitOps

### Arquitectura Kubernetes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Cluster Kubernetes                  â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Deployment  â”‚  â”‚  Deployment  â”‚            â”‚
â”‚  â”‚  demo-app    â”‚  â”‚ otel-collectorâ”‚           â”‚
â”‚  â”‚  (3 rÃ©plicas)â”‚  â”‚  (2 rÃ©plicas)â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ StatefulSet  â”‚  â”‚ StatefulSet  â”‚            â”‚
â”‚  â”‚  Prometheus  â”‚  â”‚    Tempo     â”‚            â”‚
â”‚  â”‚  (con PVC)   â”‚  â”‚  (con PVC)   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Deployment  â”‚  â”‚  Deployment  â”‚            â”‚
â”‚  â”‚   Grafana    â”‚  â”‚   Detector   â”‚            â”‚
â”‚  â”‚(LoadBalancer)â”‚  â”‚   AnomalÃ­as  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Requisitos de Recursos

| Componente | CPU Request | Memory Request | CPU Limit | Memory Limit |
|-----------|-------------|----------------|-----------|--------------|
| demo-app | 100m | 128Mi | 500m | 512Mi |
| otel-collector | 200m | 256Mi | 1000m | 512Mi |
| prometheus | 500m | 2Gi | 2000m | 4Gi |
| tempo | 500m | 1Gi | 1000m | 2Gi |
| grafana | 100m | 256Mi | 500m | 512Mi |
| anomaly-detector | 100m | 256Mi | 500m | 512Mi |

**Requisitos Totales del Cluster:** ~2 nÃºcleos CPU, ~4.5GB RAM mÃ­nimo

### Consideraciones de Escalado

```bash
# Escalar demo-app horizontalmente
kubectl scale deployment demo-app --replicas=5 -n observability

# HorizontalPodAutoscaler estÃ¡ preconfigurado
kubectl get hpa -n observability

# Escalar Prometheus verticalmente (editar StatefulSet)
kubectl edit statefulset prometheus -n observability
```

Para instrucciones detalladas de despliegue en Kubernetes, ver [k8s/README.md](k8s/README.md)

## Pipeline CI/CD

El proyecto incluye un pipeline de GitHub Actions que:
1. Ejecuta pruebas y linters
2. Construye imÃ¡genes Docker
3. Despliega a staging
4. Ejecuta smoke tests
5. Promueve a producciÃ³n (aprobaciÃ³n manual)

Para mÃ¡s informaciÃ³n, ver [docs/ci-cd/CI-CD-DOCS-INDEX.md](docs/ci-cd/CI-CD-DOCS-INDEX.md)

## Monitoreo de la Plataforma

La plataforma de observabilidad se monitorea a sÃ­ misma:
- MÃ©tricas del OTel Collector (datos descartados, latencia de exportaciÃ³n)
- Almacenamiento y rendimiento de consultas de Prometheus
- Ingesta y almacenamiento de Tempo
- Rendimiento de dashboards de Grafana

## ğŸ”§ SoluciÃ³n de Problemas

### Problemas Comunes y Soluciones

#### 1. Servicios No Inician

**Problema:** Uno o mÃ¡s contenedores fallan al iniciar

**SoluciÃ³n:**
```bash
# Verificar estado de servicios
docker-compose ps

# Ver logs para errores
docker-compose logs <nombre-servicio>

# Correcciones comunes:
# - Puerto ya en uso: Detener servicios en conflicto
# - Sin memoria: Aumentar lÃ­mite de memoria de Docker
# - Problemas de permisos: Ejecutar con permisos apropiados

# Reiniciar servicio especÃ­fico
docker-compose restart <nombre-servicio>

# Reinicio completo
docker-compose down
docker-compose up -d
```

#### 2. Sin MÃ©tricas en Grafana

**Problema:** Los dashboards muestran "Sin datos" o paneles vacÃ­os

**DiagnÃ³stico:**
```bash
# 1. Verificar si Prometheus estÃ¡ scrapeando targets
# Abrir: http://localhost:9090/targets
# Todos los targets deben mostrar estado "UP"

# 2. Verificar logs del OTel Collector
docker-compose logs otel-collector | grep -i error

# 3. Verificar que la app demo estÃ¡ enviando mÃ©tricas
docker-compose logs demo-app | grep -i "metrics"

# 4. Probar endpoint de mÃ©tricas directamente
curl http://localhost:3000/metrics
```

**SoluciÃ³n:**
```bash
# Generar trÃ¡fico para crear mÃ©tricas
.\scripts\traffic-generation\generate-continuous-traffic.ps1 -DurationSeconds 30

# Reiniciar Grafana para recargar datasources
docker-compose restart grafana

# Verificar que Prometheus tiene datos
curl http://localhost:9090/api/v1/query?query=up
```

#### 3. Sin Trazas en Tempo

**Problema:** El dashboard de Trazas Distribuidas no muestra trazas

**DiagnÃ³stico:**
```bash
# 1. Verificar que Tempo estÃ¡ recibiendo datos
docker-compose logs tempo | grep -i "received"

# 2. Verificar pipeline de trazas del OTel Collector
docker-compose logs otel-collector | grep -i "trace"

# 3. Verificar exportaciÃ³n de trazas de la app demo
docker-compose logs demo-app | grep -i "span"
```

**SoluciÃ³n:**
```bash
# Generar trÃ¡fico para crear trazas
curl http://localhost:3000/api/users
curl http://localhost:3000/api/products

# Consultar Tempo directamente
curl http://localhost:3200/api/search

# En Grafana Explore, usar consulta: {status=error}
```

#### 4. Dashboards No Cargan

**Problema:** Los dashboards de Grafana faltan o no cargan

**SoluciÃ³n:**
```bash
# 1. Reiniciar Grafana
docker-compose restart grafana

# 2. Verificar logs de provisioning
docker-compose logs grafana | grep -i "provisioning"

# 3. Verificar que existen archivos de dashboard
ls -la grafana/provisioning/dashboards/json/

# 4. Re-provisionar dashboards
docker-compose down grafana
docker-compose up -d grafana
```

#### 5. Alto Uso de Memoria

**Problema:** Los contenedores Docker consumen demasiada memoria

**SoluciÃ³n:**
```bash
# Verificar uso de memoria
docker stats

# Ajustar lÃ­mites de memoria en docker-compose.yml
# Para Prometheus:
mem_limit: 2g

# Para Tempo:
mem_limit: 1g

# Reiniciar con nuevos lÃ­mites
docker-compose up -d
```

#### 6. Detector de AnomalÃ­as No Funciona

**Problema:** No se generan alertas de anomalÃ­as

**DiagnÃ³stico:**
```bash
# Verificar logs del detector de anomalÃ­as
docker-compose logs anomaly-detector

# Verificar que puede consultar Prometheus
docker-compose exec anomaly-detector curl http://prometheus:9090/api/v1/query?query=up
```

**SoluciÃ³n:**
```bash
# Asegurar datos histÃ³ricos suficientes (7+ dÃ­as recomendado)
# Para pruebas, disparar anomalÃ­as manualmente:
.\scripts\traffic-generation\generate-test-errors.ps1 -ErrorCount 50

# Reiniciar detector de anomalÃ­as
docker-compose restart anomaly-detector
```

#### 7. Conflictos de Puertos

**Problema:** Error "Puerto ya en uso"

**SoluciÃ³n:**
```bash
# Encontrar proceso usando el puerto (Windows)
netstat -ano | findstr :3001

# Matar el proceso
taskkill /PID <process_id> /F

# O cambiar puertos en docker-compose.yml
ports:
  - "3002:3000"  # Usar puerto externo diferente
```

### Obtener Ayuda

Si aÃºn experimentas problemas:

1. **Verificar logs**: `docker-compose logs -f`
2. **Verificar prerrequisitos**: VersiÃ³n de Docker, puertos disponibles, memoria
3. **Revisar documentaciÃ³n**: Verificar READMEs especÃ­ficos de componentes
4. **Buscar issues**: Buscar problemas similares en GitHub issues
5. **Crear un issue**: Proporcionar logs, salida de docker-compose ps y pasos para reproducir

### Scripts de DiagnÃ³stico

Proporcionamos scripts de diagnÃ³stico para ayudar a solucionar problemas:

```powershell
# Verificar si las mÃ©tricas estÃ¡n fluyendo
.\scripts\utilities\verify-error-rate.ps1

# Diagnosticar pipeline de telemetrÃ­a
.\scripts\utilities\diagnose-telemetry.bat

# Listar mÃ©tricas disponibles
.\scripts\utilities\list-available-metrics.ps1

# Verificar dashboards
.\scripts\utilities\verify-dashboards.ps1
```

### Endpoints de Health Check

Todos los servicios exponen endpoints de health check:

```bash
# Demo App
curl http://localhost:3000/health
curl http://localhost:3000/ready

# Prometheus
curl http://localhost:9090/-/healthy

# Tempo
curl http://localhost:3200/ready

# Grafana
curl http://localhost:3001/api/health
```

## Consideraciones de Rendimiento

- **Prometheus**: Ajustar perÃ­odo de retenciÃ³n basado en capacidad de almacenamiento
- **Tempo**: Configurar retenciÃ³n de trazas apropiada
- **OTel Collector**: Ajustar tamaÃ±o de batch y lÃ­mites de memoria
- **Detector de AnomalÃ­as**: Ajustar intervalo de verificaciÃ³n basado en volumen de mÃ©tricas

## Seguridad

Para despliegues de producciÃ³n:
- Cambiar credenciales predeterminadas de Grafana
- Habilitar autenticaciÃ³n en Prometheus y Tempo
- Usar polÃ­ticas de red para restringir acceso
- Almacenar secretos en sistemas seguros de gestiÃ³n de secretos

## Contribuir

Â¡Las contribuciones son bienvenidas! Por favor:
1. Hacer fork del repositorio
2. Crear una rama de feature
3. Hacer cambios con pruebas
4. Enviar un pull request

## Licencia

[Tu Licencia AquÃ­]

## Soporte

Para problemas y preguntas:
- Abrir un issue en GitHub
- Verificar la secciÃ³n de soluciÃ³n de problemas
- Revisar logs de componentes

## Hoja de Ruta

Mejoras futuras:
- IntegraciÃ³n de logs con Loki
- IntegraciÃ³n con service mesh (Istio/Linkerd)
- AIOps avanzado (anÃ¡lisis de causa raÃ­z)
- Recomendaciones de optimizaciÃ³n de costos
- Soporte multi-tenancy
- IntegraciÃ³n con chaos engineering

## Referencias

- [DocumentaciÃ³n OpenTelemetry](https://opentelemetry.io/docs/)
- [DocumentaciÃ³n Prometheus](https://prometheus.io/docs/)
- [DocumentaciÃ³n Grafana Tempo](https://grafana.com/docs/tempo/)
- [Libro Google SRE - SLIs, SLOs y Presupuestos de Error](https://sre.google/sre-book/service-level-objectives/)

---

## ğŸ“š DocumentaciÃ³n Adicional

Para mÃ¡s informaciÃ³n detallada, consulta:

- **[Ãndice de DocumentaciÃ³n](DOCUMENTATION_INDEX.md)** - Ãndice completo de toda la documentaciÃ³n
- **[Reportes de ValidaciÃ³n](docs/validation-reports/VALIDATION_INDEX.md)** - Validaciones completas del sistema
- **[GuÃ­as de Usuario](docs/guides/)** - GuÃ­as detalladas de uso y configuraciÃ³n
- **[DocumentaciÃ³n CI/CD](docs/ci-cd/CI-CD-DOCS-INDEX.md)** - InformaciÃ³n del pipeline CI/CD
- **[ResÃºmenes TÃ©cnicos](docs/summaries/)** - ResÃºmenes de tareas y correcciones

---

**Â¿Preguntas? Consulta el [Ãndice de DocumentaciÃ³n](DOCUMENTATION_INDEX.md) para encontrar la informaciÃ³n que necesitas.**
